{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2e469aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as tf\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from ckpt_manager import CheckpointManager\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa06ef6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087d56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetDecBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, upsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(in_channels))\n",
    "        if stride != 1:\n",
    "            self.conv2 = nn.Sequential(\n",
    "                            nn.Upsample(scale_factor=stride),\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.BatchNorm2d(out_channels))\n",
    "            self.shortcut = nn.Sequential(\n",
    "                            nn.Upsample(scale_factor=stride),\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1))\n",
    "        else:\n",
    "            self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(out_channels))\n",
    "            self.shortcut = nn.Sequential()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b2f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inchannel = 64\n",
    "        backbone = torchvision.models.resnet18(weights=\"DEFAULT\")\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            backbone.conv1,\n",
    "            backbone.bn1,\n",
    "            backbone.relu,\n",
    "            backbone.maxpool\n",
    "        )\n",
    "        self.layer1 = backbone.layer1\n",
    "        self.layer2 = backbone.layer2\n",
    "        self.layer3 = backbone.layer3\n",
    "        self.layer4 = backbone.layer4\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c333134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18Decoder(nn.Module):\n",
    "    def __init__(self, Block):\n",
    "        super().__init__()\n",
    "        self.inchannel = 512\n",
    "        self.up = nn.Upsample(scale_factor=2)\n",
    "        self.layer1 = self.make_layer(Block, 256, 2, stride=2)\n",
    "        self.layer2 = self.make_layer(Block, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(Block, 64, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(Block, 64, 2, stride=1)\n",
    "        self.resize = nn.Sequential(\n",
    "                            nn.Upsample(scale_factor=4),\n",
    "                            nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, 512, 8, 8)\n",
    "        out = self.up(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.resize(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6639ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetAutoencoder(nn.Module):\n",
    "    def __init__(self, quantize_factor):\n",
    "        super().__init__()\n",
    "        self.enc = ResNet18Encoder()\n",
    "        self.dec = ResNet18Decoder(ResNetDecBlock)\n",
    "        self.quantize_factor = quantize_factor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.enc(x)\n",
    "        out = torch.clamp(out, 0.0, 1.0)\n",
    "        out = out + (1 / 2 ** self.quantize_factor) * (torch.rand_like(out) * 0.5 - 0.5)\n",
    "        out = self.dec(out)\n",
    "        return F.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f84cbc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tf.Compose(\n",
    "        [\n",
    "         tf.ToTensor()\n",
    "        ]\n",
    ")\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8721b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder('universal-dataset', transform=transform)\n",
    "loader = td.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ca3edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf model_B=2\n",
    "# !rm -rf model_B=256\n",
    "# !rm -rf model_B=8\n",
    "# !rm -rf training_checkpoints_B=2\n",
    "# !rm -rf training_checkpoints_B=256\n",
    "# !rm -rf training_checkpoints_B=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e7eaf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir training_checkpoints_B=10\n",
    "!mkdir training_checkpoints_B=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38efcde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetAutoencoder(2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4b37ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = CheckpointManager(\n",
    "    assets={\n",
    "        'model' : model.state_dict()\n",
    "    },\n",
    "    directory='training_checkpoints_B=2',\n",
    "    file_name='ResNetAutoencoder',\n",
    "    maximum=10,\n",
    "    file_format='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67c97cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fd38ffd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:42,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 99 | loss: 0.0355590483173728\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:23,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 199 | loss: 0.022535147368907927\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [02:04,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 299 | loss: 0.019365734197199346\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:46,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 399 | loss: 0.01797392622567713\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:27,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 499 | loss: 0.016411674367263915\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [04:09,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 599 | loss: 0.01515758628025651\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "699it [04:50,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 699 | loss: 0.01469973341561854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [04:50,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [05:32,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 799 | loss: 0.013909212425351142\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "900it [06:13,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 899 | loss: 0.012989940559491516\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [06:55,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 999 | loss: 0.01289048781618476\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1100it [07:36,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 1099 | loss: 0.012800270058214665\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1200it [08:18,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 1199 | loss: 0.012175543988123537\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1300it [09:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 1299 | loss: 0.011981275482103228\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [09:42,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 1399 | loss: 0.01179324796423316\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1500it [10:24,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 1499 | loss: 0.011281449245288969\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_13.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1600it [11:06,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 1599 | loss: 0.011265694359317423\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_13.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1700it [11:47,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 1699 | loss: 0.011051364298909903\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1800it [12:29,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 1799 | loss: 0.010582346022129058\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1900it [13:10,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 1899 | loss: 0.010553488554432989\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [13:52,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | iter: 1999 | loss: 0.010450115036219359\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2071it [14:21,  2.40it/s]\n",
      "100it [00:41,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | iter: 99 | loss: 0.010190647235140205\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:23,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | iter: 199 | loss: 0.010102741103619337\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [02:04,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | iter: 299 | loss: 0.00978135091252625\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_17.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:46,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | iter: 399 | loss: 0.009659050046466292\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_17.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:28,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | iter: 499 | loss: 0.009665857595391571\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_18.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [04:09,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | iter: 599 | loss: 0.009516026130877436\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_18.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [04:51,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | iter: 699 | loss: 0.009208576139062643\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_19.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [05:33,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | iter: 799 | loss: 0.009325693282298743\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_19.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "900it [06:15,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | iter: 899 | loss: 0.009173358106054366\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_20.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [06:57,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | iter: 999 | loss: 0.008868359224870802\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_21.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1100it [07:38,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | iter: 1099 | loss: 0.008960101841948927\n",
      "Saved states to training_checkpoints_B=2/ResNetAutoencoder_22.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1125it [07:49,  2.38it/s]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "SAVE_LOG_ITERS = 100\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (batch, _) in tqdm(enumerate(loader)):\n",
    "        batch = batch.cuda()\n",
    "        \n",
    "        predicted = model(batch)\n",
    "        \n",
    "        loss = criterion(predicted, batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if (i + 1) % SAVE_LOG_ITERS == 0:\n",
    "            print(f\"Epoch: {epoch} | iter: {i} | loss: {np.array(losses[-SAVE_LOG_ITERS:]).mean()}\")\n",
    "            manager.save()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9680d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model_B=2\n",
    "torch.save(model.enc.state_dict(), 'model_B=2/encoder.model')\n",
    "torch.save(model.dec.state_dict(), 'model_B=2/decoder.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetAutoencoder(10).cuda()\n",
    "manager = CheckpointManager(\n",
    "    assets={\n",
    "        'model' : model.state_dict()\n",
    "    },\n",
    "    directory='training_checkpoints_B=10',\n",
    "    file_name='ResNetAutoencoder',\n",
    "    maximum=10,\n",
    "    file_format='pt'\n",
    ")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "\n",
    "EPOCHS = 3\n",
    "SAVE_LOG_ITERS = 100\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (batch, _) in tqdm(enumerate(loader)):\n",
    "        batch = batch.cuda()\n",
    "        \n",
    "        predicted = model(batch)\n",
    "        \n",
    "        loss = criterion(predicted, batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if (i + 1) % SAVE_LOG_ITERS == 0:\n",
    "            print(f\"Epoch: {epoch} | iter: {i} | loss: {np.array(losses[-SAVE_LOG_ITERS:]).mean()}\")\n",
    "            manager.save()\n",
    "    scheduler.step()\n",
    "\n",
    "!mkdir model_B=10\n",
    "torch.save(model.enc.state_dict(), 'model_B=10/encoder.model')\n",
    "torch.save(model.dec.state_dict(), 'model_B=10/decoder.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9524acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}