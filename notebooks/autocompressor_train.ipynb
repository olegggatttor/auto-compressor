{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2e469aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as tf\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from ckpt_manager import CheckpointManager\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa06ef6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087d56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetDecBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, upsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(in_channels))\n",
    "        if stride != 1:\n",
    "            self.conv2 = nn.Sequential(\n",
    "                            nn.Upsample(scale_factor=stride),\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.BatchNorm2d(out_channels))\n",
    "            self.shortcut = nn.Sequential(\n",
    "                            nn.Upsample(scale_factor=stride),\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1))\n",
    "        else:\n",
    "            self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                        nn.BatchNorm2d(out_channels))\n",
    "            self.shortcut = nn.Sequential()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b2f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inchannel = 64\n",
    "        backbone = torchvision.models.resnet18(weights=\"DEFAULT\")\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            backbone.conv1,\n",
    "            backbone.bn1,\n",
    "            backbone.relu,\n",
    "            backbone.maxpool\n",
    "        )\n",
    "        self.layer1 = backbone.layer1\n",
    "        self.layer2 = backbone.layer2\n",
    "        self.layer3 = backbone.layer3\n",
    "        self.layer4 = backbone.layer4\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c333134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18Decoder(nn.Module):\n",
    "    def __init__(self, Block):\n",
    "        super().__init__()\n",
    "        self.inchannel = 512\n",
    "        self.up = nn.Upsample(scale_factor=2)\n",
    "        self.layer1 = self.make_layer(Block, 256, 2, stride=2)\n",
    "        self.layer2 = self.make_layer(Block, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(Block, 64, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(Block, 64, 2, stride=1)\n",
    "        self.resize = nn.Sequential(\n",
    "                            nn.Upsample(scale_factor=4),\n",
    "                            nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, 512, 8, 8)\n",
    "        out = self.up(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.resize(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6639ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetAutoencoder(nn.Module):\n",
    "    def __init__(self, quantize_factor):\n",
    "        super().__init__()\n",
    "        self.enc = ResNet18Encoder()\n",
    "        self.dec = ResNet18Decoder(ResNetDecBlock)\n",
    "        self.quantize_factor = quantize_factor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.enc(x)\n",
    "        out = F.sigmoid(out)\n",
    "        out = out + (1 / 2 ** self.quantize_factor) * (torch.rand_like(out) * 0.5 - 0.5)\n",
    "        out = torch.log(out / (1 - out))\n",
    "        out = self.dec(out)\n",
    "        return F.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f84cbc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tf.Compose(\n",
    "        [\n",
    "         tf.ToTensor()\n",
    "        ]\n",
    ")\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8721b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder('universal-dataset', transform=transform)\n",
    "loader = td.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38efcde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetAutoencoder(2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b37ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = CheckpointManager(\n",
    "    assets={\n",
    "        'model' : model.state_dict()\n",
    "    },\n",
    "    directory='training_checkpoints_B=2',\n",
    "    file_name='ResNetAutoencoder',\n",
    "    maximum=5,\n",
    "    file_format='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8c98c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading states from training_checkpoints_B=2/ResNetAutoencoder_132.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_state = manager.load()\n",
    "model.load_state_dict(loaded_state['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67c97cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4 * 0.7)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.7)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fd38ffd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "SAVE_LOG_ITERS = 100\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (batch, _) in tqdm(enumerate(loader)):\n",
    "        batch = batch.cuda()\n",
    "        \n",
    "        predicted = model(batch)\n",
    "        \n",
    "        loss = criterion(predicted, batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if (i + 1) % SAVE_LOG_ITERS == 0:\n",
    "            print(f\"Epoch: {epoch} | iter: {i} | loss: {np.array(losses[-SAVE_LOG_ITERS:]).mean()}\")\n",
    "            manager.save()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9680d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.enc.state_dict(), 'model_B=8/encoder.model')\n",
    "torch.save(model.dec.state_dict(), 'model_B=8/decoder.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9810a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.enc.state_dict(), 'model_B=2/encoder.model')\n",
    "torch.save(model.dec.state_dict(), 'model_B=2/decoder.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ad32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}